# ğŸš€ InserÃ§Ã£o de Dados da API do LinkedIn no Google BigQuery  

## ğŸ“Œ IntroduÃ§Ã£o  

Este projeto fornece um **script automatizado** para extrair dados de campanhas do LinkedIn Ads e inseri-los no Google BigQuery.  

## âš™ï¸ ConfiguraÃ§Ã£o  

### 1ï¸âƒ£ Criar um tÃ³pico Pub/Sub  
Antes de implantar a funÃ§Ã£o na nuvem, crie um tÃ³pico no Pub/Sub:  

```bash
gcloud pubsub topics create linkedin_run
```

### 2ï¸âƒ£ Publicar a Cloud Function  

Implante a funÃ§Ã£o no Google Cloud Functions para processar os dados:  

```bash
gcloud functions deploy get_linkedin_data \
  --runtime python39 \
  --trigger-topic linkedin_run \
  --timeout=540 \
  --memory=256MB
```

---

## ğŸ”„ ExtraÃ§Ã£o de Dados  

A extraÃ§Ã£o pode ser feita com diferentes intervalos de tempo. Para os Ãºltimos 90 dias, utilize `past_90`.  

### ğŸ”¹ Comando para ExtraÃ§Ã£o  
No **Cloud Shell**, execute:  

```bash
gcloud pubsub topics publish linkedin_run \
  --message="get_linkedin" \
  --attribute=project_id=PROJECT_ID,dataset_id=DATASET_ID,table_id=TABLE_ID,account_id=ACCOUNT_ID,date_preset=DATE_PRESET
```

### ğŸ”¹ ParÃ¢metros  

| ParÃ¢metro      | DescriÃ§Ã£o |
|---------------|--------------|
| **PROJECT_ID**  | Nome do projeto no GCP |
| **DATASET_ID**  | Nome do banco de dados |
| **TABLE_ID**    | Nome da tabela no BigQuery |
| **ACCOUNT_ID**  | ID da conta de anÃºncios no LinkedIn |
| **MESSAGE**     | `"get_linkedin"` (fixo) |
| **DATE_PRESET** | PerÃ­odo da extraÃ§Ã£o (`"past_90"` ou `"yesterday"`) |

ğŸ“Œ **Importante:**  
- O **ACCESS_TOKEN** e **REFRESH_TOKEN** sÃ£o necessÃ¡rios para a API do LinkedIn e devem estar no arquivo `ln_cred.json`.  
- Tokens podem ser obtidos seguindo a [documentaÃ§Ã£o oficial do LinkedIn](https://docs.microsoft.com/en-us/linkedin/marketing/getting-access).  

---

## ğŸ”‘ RenovaÃ§Ã£o do Access Token  

A renovaÃ§Ã£o do **ACCESS_TOKEN** ocorre **automaticamente** caso um erro de token invÃ¡lido seja detectado.  
Se a renovaÃ§Ã£o automÃ¡tica falhar, siga estes passos:  

### ğŸ”¹ RenovaÃ§Ã£o Manual  
1. Execute o script de renovaÃ§Ã£o:  

   ```bash
   python refresh_tokens.py
   ```

2. Substitua as credenciais no arquivo **ln_cred.json** da Cloud Functions.  
3. Confirme que o arquivo estÃ¡ no **bucket** correto (`extractors-ads`).  

---

## ğŸ“… Agendamento DiÃ¡rio da ExtraÃ§Ã£o  

Podemos automatizar a extraÃ§Ã£o diÃ¡ria dos dados criando um **Cloud Scheduler Job**.  

### ğŸ”¹ Criando um Job DiÃ¡rio  
```bash
gcloud beta scheduler jobs create pubsub job_name \
  --time-zone "America/Sao_Paulo" \
  --schedule "1 5 * * *" \
  --topic linkedin_run \
  --message-body "get_linkedin" \
  --attributes project_id=PROJECT_ID,dataset_id=DATASET_ID,table_id=TABLE_ID,account_id=ACCOUNT_ID,date_preset="yesterday"
```

### ğŸ”¹ ParÃ¢metros Explicados  
- **job_name** â†’ Nome do job, personalizar conforme necessÃ¡rio.  
- **time-zone** â†’ Define o fuso horÃ¡rio (ex: `America/Sao_Paulo`).  
- **schedule** â†’ Define a frequÃªncia da extraÃ§Ã£o (`1 5 * * *` = todos os dias Ã s 5AM).  
- **date_preset="yesterday"** â†’ ExtraÃ§Ã£o diÃ¡ria apenas do **dia anterior**.  

---

## ğŸ†˜ SoluÃ§Ã£o de Problemas  

Caso algo saia errado e a tabela precise ser corrigida, siga estas etapas:  

1ï¸âƒ£ **Limpar a tabela antes de uma nova carga:**  
```sql
TRUNCATE TABLE `meu_projeto.meu_dataset.minha_tabela`
```

2ï¸âƒ£ **Rodar a extraÃ§Ã£o novamente com `past_90`** para recuperar os dados dos Ãºltimos 90 dias.  

---

## âœï¸ Autor  
ğŸ‘¤ **Carlos Junior**  

---
